{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0rYYIF98xZq"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwFrDWCV9IHv"
   },
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "b_JMPzjr8xZr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import pandas as pd\n",
    "from seqeval.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>utterances</th>\n",
       "      <th>IOB Slot tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>who plays luke on star wars new hope</td>\n",
       "      <td>O O B_char O B_movie I_movie I_movie I_movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>show credits for the godfather</td>\n",
       "      <td>O O O B_movie I_movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>who was the main actor in the exorcist</td>\n",
       "      <td>O O O O O O B_movie I_movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>find the female actress from the movie she 's ...</td>\n",
       "      <td>O O O O O O O B_movie I_movie I_movie I_movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>who played dory on finding nemo</td>\n",
       "      <td>O O B_char O B_movie I_movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                         utterances  \\\n",
       "0   1               who plays luke on star wars new hope   \n",
       "1   2                     show credits for the godfather   \n",
       "2   3             who was the main actor in the exorcist   \n",
       "3   4  find the female actress from the movie she 's ...   \n",
       "4   5                    who played dory on finding nemo   \n",
       "\n",
       "                                   IOB Slot tags  \n",
       "0   O O B_char O B_movie I_movie I_movie I_movie  \n",
       "1                          O O O B_movie I_movie  \n",
       "2                    O O O O O O B_movie I_movie  \n",
       "3  O O O O O O O B_movie I_movie I_movie I_movie  \n",
       "4                   O O B_char O B_movie I_movie  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/hw2_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>utterances</th>\n",
       "      <th>IOB Slot tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>who plays luke on star wars new hope</td>\n",
       "      <td>O O B_char O B_movie I_movie I_movie I_movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>show credits for the godfather</td>\n",
       "      <td>O O O B_movie I_movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>who was the main actor in the exorcist</td>\n",
       "      <td>O O O O O O B_movie I_movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>find the female actress from the movie she 's ...</td>\n",
       "      <td>O O O O O O O B_movie I_movie I_movie I_movie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>who played dory on finding nemo</td>\n",
       "      <td>O O B_char O B_movie I_movie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                         utterances  \\\n",
       "0   1               who plays luke on star wars new hope   \n",
       "1   2                     show credits for the godfather   \n",
       "2   3             who was the main actor in the exorcist   \n",
       "3   4  find the female actress from the movie she 's ...   \n",
       "4   5                    who played dory on finding nemo   \n",
       "\n",
       "                                   IOB Slot tags  \n",
       "0   O O B_char O B_movie I_movie I_movie I_movie  \n",
       "1                          O O O B_movie I_movie  \n",
       "2                    O O O O O O B_movie I_movie  \n",
       "3  O O O O O O O B_movie I_movie I_movie I_movie  \n",
       "4                   O O B_char O B_movie I_movie  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/hw2_train.csv')\n",
    "\n",
    "# Display the first few rows to confirm data structure\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tag</th>\n",
       "      <th>Count</th>\n",
       "      <th>Proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O</td>\n",
       "      <td>10505</td>\n",
       "      <td>0.721101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I_movie</td>\n",
       "      <td>1146</td>\n",
       "      <td>0.078666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B_movie</td>\n",
       "      <td>1016</td>\n",
       "      <td>0.069742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B_person</td>\n",
       "      <td>194</td>\n",
       "      <td>0.013317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B_director</td>\n",
       "      <td>185</td>\n",
       "      <td>0.012699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I_person</td>\n",
       "      <td>175</td>\n",
       "      <td>0.012013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I_director</td>\n",
       "      <td>168</td>\n",
       "      <td>0.011532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B_producer</td>\n",
       "      <td>164</td>\n",
       "      <td>0.011258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B_country</td>\n",
       "      <td>153</td>\n",
       "      <td>0.010502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>B_mpaa_rating</td>\n",
       "      <td>141</td>\n",
       "      <td>0.009679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>B_language</td>\n",
       "      <td>119</td>\n",
       "      <td>0.008169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I_producer</td>\n",
       "      <td>114</td>\n",
       "      <td>0.007825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B_cast</td>\n",
       "      <td>106</td>\n",
       "      <td>0.007276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I_cast</td>\n",
       "      <td>105</td>\n",
       "      <td>0.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B_subject</td>\n",
       "      <td>95</td>\n",
       "      <td>0.006521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B_genre</td>\n",
       "      <td>71</td>\n",
       "      <td>0.004874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I_subject</td>\n",
       "      <td>33</td>\n",
       "      <td>0.002265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I_language</td>\n",
       "      <td>17</td>\n",
       "      <td>0.001167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B_char</td>\n",
       "      <td>15</td>\n",
       "      <td>0.001030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I_country</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I_mpaa_rating</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>I_genre</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B_release_year</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I_char</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I_release_year</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B_location</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I-movie</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>O¬¥O</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Tag  Count  Proportion\n",
       "0                O  10505    0.721101\n",
       "3          I_movie   1146    0.078666\n",
       "2          B_movie   1016    0.069742\n",
       "5         B_person    194    0.013317\n",
       "7       B_director    185    0.012699\n",
       "6         I_person    175    0.012013\n",
       "8       I_director    168    0.011532\n",
       "14      B_producer    164    0.011258\n",
       "12       B_country    153    0.010502\n",
       "21   B_mpaa_rating    141    0.009679\n",
       "23      B_language    119    0.008169\n",
       "15      I_producer    114    0.007825\n",
       "16          B_cast    106    0.007276\n",
       "17          I_cast    105    0.007208\n",
       "18       B_subject     95    0.006521\n",
       "19         B_genre     71    0.004874\n",
       "26       I_subject     33    0.002265\n",
       "24      I_language     17    0.001167\n",
       "1           B_char     15    0.001030\n",
       "13       I_country     12    0.000824\n",
       "22   I_mpaa_rating     12    0.000824\n",
       "25         I_genre      5    0.000343\n",
       "9   B_release_year      5    0.000343\n",
       "4           I_char      5    0.000343\n",
       "10  I_release_year      3    0.000206\n",
       "11      B_location      2    0.000137\n",
       "20         I-movie      1    0.000069\n",
       "27            O¬¥O      1    0.000069"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the tags from all rows into a single list for counting\n",
    "all_tags = [tag for tags in df['IOB Slot tags'].str.split() for tag in tags]\n",
    "\n",
    "# Count occurrences of each tag\n",
    "tag_counts = Counter(all_tags)\n",
    "tag_counts_df = pd.DataFrame(tag_counts.items(), columns=['Tag', 'Count']).sort_values(by='Count', ascending=False)\n",
    "tag_counts_df['Proportion'] = tag_counts_df['Count'] / tag_counts_df['Count'].sum()\n",
    "\n",
    "# Display tag distribution table\n",
    "tag_counts_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mean': 6.307525951557094, 'Min': 1, 'Max': 21}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate token counts for each utterance\n",
    "df['Token Count'] = df['utterances'].str.split().apply(len)\n",
    "\n",
    "# Get summary statistics for token counts\n",
    "token_count_stats = {\n",
    "    \"Mean\": df['Token Count'].mean(),\n",
    "    \"Min\": df['Token Count'].min(),\n",
    "    \"Max\": df['Token Count'].max()\n",
    "}\n",
    "\n",
    "# Display token count statistics\n",
    "token_count_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot tag distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(tag_counts_df['Tag'], tag_counts_df['Count'], color='skyblue')\n",
    "plt.xlabel('Tag')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Tag Distribution in Dataset')\n",
    "plt.xticks(rotation=90)\n",
    "# save\n",
    "plt.savefig('tag_distribution.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/hw2_val.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming separate files for splits, adjust file paths as needed\u001b[39;00m\n\u001b[1;32m      2\u001b[0m train_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/hw2_train.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m val_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/hw2_val.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/hw2_test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Calculate number of samples in each split\u001b[39;00m\n",
      "File \u001b[0;32m~/nlp_ms/243/hw2/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nlp_ms/243/hw2/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/nlp_ms/243/hw2/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/nlp_ms/243/hw2/venv/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/nlp_ms/243/hw2/venv/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/hw2_val.csv'"
     ]
    }
   ],
   "source": [
    "# Assuming separate files for splits, adjust file paths as needed\n",
    "train_df = pd.read_csv('data/hw2_train.csv')\n",
    "val_df = pd.read_csv('data/hw2_val.csv')\n",
    "test_df = pd.read_csv('data/hw2_test.csv')\n",
    "\n",
    "# Calculate number of samples in each split\n",
    "split_counts = {\n",
    "    \"Train Set\": len(train_df),\n",
    "    \"Validation Set\": len(val_df),\n",
    "    \"Test Set\": len(test_df)\n",
    "}\n",
    "\n",
    "# Calculate proportions\n",
    "total_samples = sum(split_counts.values())\n",
    "split_proportions = {key: count / total_samples for key, count in split_counts.items()}\n",
    "\n",
    "# Display split counts and proportions\n",
    "split_counts, split_proportions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nBgCNpjQ8xZs"
   },
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "ZLTcKz-d8xZt"
   },
   "outputs": [],
   "source": [
    "# create if it doesn't exist\n",
    "model_dir_name = \"lstm_glove_unfrozen\"\n",
    "\n",
    "timestamp = pd.Timestamp.now().strftime('%m_%d_%H%M')\n",
    "MODEL_DIR_NAME = f\"model_{model_dir_name or timestamp}\"\n",
    "\n",
    "if not os.path.exists(MODEL_DIR_NAME):\n",
    "    os.makedirs(MODEL_DIR_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10LeghCA8xZt"
   },
   "source": [
    "### Documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_bmR2qFE8xZu"
   },
   "outputs": [],
   "source": [
    "def create_versioned_dir(base_dir):\n",
    "    \"\"\" create a new versioned directory \"\"\"\n",
    "    os.makedirs(base_dir, exist_ok=True)\n",
    "    existing_versions = [int(d[1:]) for d in os.listdir(base_dir) if d.startswith('v') and d[1:].isdigit()]\n",
    "    version_num = max(existing_versions, default=0) + 1\n",
    "    version_dir = os.path.join(base_dir, f'v{version_num}')\n",
    "    os.makedirs(version_dir, exist_ok=True)\n",
    "    return version_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SLs8HvVk8xZu"
   },
   "outputs": [],
   "source": [
    "def write_json(data, filename):\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    # print(f\"Saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "5wwX_Ivz8xZu"
   },
   "outputs": [],
   "source": [
    "from ctypes import BigEndianStructure\n",
    "def get_config_json(embedding_dim, hidden_dim, batch_size, learning_rate, num_epochs, patience, dropout_prob, embedding_matrix_name, train_test_split, bidirectional, num_layers):\n",
    "    return {\n",
    "        \"embedding_dim\": embedding_dim,\n",
    "        \"hidden_dim\": hidden_dim,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"epochs\": num_epochs,\n",
    "        \"early_stopping_patience\": patience,\n",
    "        \"dropout_prob\": dropout_prob,\n",
    "        \"embedding_matrix\": embedding_matrix_name,\n",
    "        \"train_test_split\": train_test_split,\n",
    "        \"bidirectional\": bidirectional,\n",
    "        \"num_layers\": num_layers,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NZW4q1DD8xZv"
   },
   "outputs": [],
   "source": [
    "def get_training_summary_json(train_losses, val_losses, val_f1_scores, early_stopping_epoch):\n",
    "    return {\n",
    "        \"best_epoch\": {\n",
    "            \"epoch\": val_f1_scores.index(max(val_f1_scores)) + 1,\n",
    "            \"val_loss\": val_losses[val_f1_scores.index(max(val_f1_scores))],\n",
    "            \"val_f1\": max(val_f1_scores)\n",
    "        },\n",
    "        \"early_stopping\": {\n",
    "            \"epoch_triggered\": early_stopping_epoch,\n",
    "            \"reason\": \"Early stopping triggered after epoch {}\".format(early_stopping_epoch)\n",
    "        },\n",
    "        \"epochs\": [\n",
    "            {\"epoch\": i + 1, \"train_loss\": train_losses[i], \"val_loss\": val_losses[i], \"val_f1\": val_f1_scores[i]}\n",
    "            for i in range(len(train_losses))\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Z9884Kvu8xZv"
   },
   "outputs": [],
   "source": [
    "def get_val_results_json(true_tags, pred_tags, tag_names):\n",
    "    # flatten the tags\n",
    "    true_tags_flat = [tag for seq in true_tags for tag in seq]\n",
    "    pred_tags_flat = [tag for seq in pred_tags for tag in seq]\n",
    "\n",
    "    return {\n",
    "        \"true_tags\": true_tags_flat,\n",
    "        \"predicted_tags\": pred_tags_flat,\n",
    "        \"tag_names\": tag_names\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GQsa6LG58xZv"
   },
   "outputs": [],
   "source": [
    "def get_test_results_json(avg_test_loss, test_f1, test_report):\n",
    "    return {\n",
    "        \"avg_test_loss\": float(avg_test_loss),\n",
    "        \"f1_score\": float(test_f1),\n",
    "        \"classification_report\": test_report\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "JrjsCXHR8xZv"
   },
   "outputs": [],
   "source": [
    "def save_performance_table(model_dir, true_tags, pred_tags):\n",
    "    \"\"\" Save performance table to a CSV file \"\"\"\n",
    "    print(f\"Saving performance table to '{model_dir}'\")\n",
    "    report = classification_report(true_tags, pred_tags, output_dict=True)\n",
    "    df_report = pd.DataFrame(report).transpose().round(3)\n",
    "    filepath = f\"{model_dir}/performance_table.csv\"\n",
    "    df_report.to_csv(filepath)\n",
    "    print(f\"Performance table saved to '{filepath}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGaVbqIf8xZv"
   },
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "P_EMJ6Hw8xZv"
   },
   "outputs": [],
   "source": [
    "def plot_loss_from_file(model_dir):\n",
    "    # Load training summary data\n",
    "    with open(f\"{model_dir}/metrics.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract lists of training and validation losses\n",
    "    train_losses = [entry[\"train_loss\"] for entry in data[\"epochs\"]]\n",
    "    val_losses = [entry[\"val_loss\"] for entry in data[\"epochs\"]]\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    # Plot the loss curve\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Save plot to the model's directory\n",
    "    plt.savefig(f\"{model_dir}/loss_curve.png\")\n",
    "    # print(f\"Loss curve saved to '{model_dir}/loss_curve.png'\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "NugJiEBo8xZv"
   },
   "outputs": [],
   "source": [
    "def plot_f1_from_file(model_dir):\n",
    "    # Load training summary data\n",
    "    with open(f\"{model_dir}/metrics.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract list of validation F1 scores\n",
    "    val_f1_scores = [entry[\"val_f1\"] for entry in data[\"epochs\"]]\n",
    "    epochs = range(1, len(val_f1_scores) + 1)\n",
    "\n",
    "    # Plot the F1 score curve\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, val_f1_scores, label='Validation F1 Score')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('Validation F1 Score Over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Save plot to the model's directory\n",
    "    plt.savefig(f\"{model_dir}/f1_curve.png\")\n",
    "    # print(f\"F1 score curve saved to '{model_dir}/f1_curve.png'\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "gs-ODRSt8xZv"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model_dir):\n",
    "    # Load test results data\n",
    "    with open(f\"{model_dir}/metrics/test_results.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract confusion matrix and tag names\n",
    "    cm = data[\"confusion_matrix\"]\n",
    "    tag_names = data[\"tag_names\"]\n",
    "\n",
    "    # Plot the confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=tag_names, yticklabels=tag_names)\n",
    "    plt.xlabel('Predicted Tag')\n",
    "    plt.ylabel('True Tag')\n",
    "    plt.title('Confusion Matrix of Tag Predictions')\n",
    "\n",
    "    # Save plot to the model's directory\n",
    "    plt.savefig(f\"{model_dir}/plots/confusion_matrix.png\")\n",
    "    # print(f\"Confusion matrix saved to '{model_dir}/plots/confusion_matrix.png'\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5h-1mPgB8xZw"
   },
   "outputs": [],
   "source": [
    "def plot_classification_report(model_dir):\n",
    "    # Load test results data\n",
    "    with open(f\"{model_dir}/metrics/test_results.json\", \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract tag-specific F1 scores from the report\n",
    "    report = data[\"classification_report\"]\n",
    "    tag_names = [tag for tag in report if tag not in [\"accuracy\", \"macro avg\", \"weighted avg\"]]\n",
    "    f1_scores = [report[tag][\"f1-score\"] for tag in tag_names]\n",
    "\n",
    "    # Plot F1 scores for each tag\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(tag_names, f1_scores, color='skyblue')\n",
    "    plt.xlabel('F1 Score')\n",
    "    plt.title('Tag-wise F1 Score')\n",
    "\n",
    "    # Save plot to the model's directory\n",
    "    plt.savefig(f\"{model_dir}/plots/classification_report.png\")\n",
    "    # print(f\"Classification report plot saved to '{model_dir}/plots/classification_report.png'\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kK3EFem28xZw"
   },
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "V6XYSs3Q8xZw"
   },
   "outputs": [],
   "source": [
    "class SlotTaggingDataset(Dataset):\n",
    "    def __init__(self, data, token_vocab=None, tag_vocab=None, training=True):\n",
    "        # Create vocabularies if training\n",
    "        if training:\n",
    "            self.token_vocab = {'<PAD>': 0, '<UNK>': 1}\n",
    "            self.tag_vocab = {'<PAD>': 0}\n",
    "\n",
    "            # Build vocab from tokens and tags\n",
    "            for _, row in data.iterrows():\n",
    "                tokens = row['utterances'].split()\n",
    "                tags = row['IOB Slot tags'].split() if 'IOB Slot tags' in row else None\n",
    "\n",
    "                for token in tokens:\n",
    "                    if token not in self.token_vocab:\n",
    "                        self.token_vocab[token] = len(self.token_vocab)\n",
    "                if tags:\n",
    "                    for tag in tags:\n",
    "                        if tag not in self.tag_vocab:\n",
    "                            self.tag_vocab[tag] = len(self.tag_vocab)\n",
    "        else:\n",
    "            assert token_vocab is not None and tag_vocab is not None\n",
    "            self.token_vocab = token_vocab\n",
    "            self.tag_vocab = tag_vocab\n",
    "\n",
    "        self.corpus_token_ids = [\n",
    "            torch.tensor([self.token_vocab.get(token, self.token_vocab['<UNK>']) for token in row['utterances'].split()])\n",
    "            for _, row in data.iterrows()\n",
    "        ]\n",
    "\n",
    "        # Only add tag ids if they exist\n",
    "        if 'IOB Slot tags' in data.columns:\n",
    "            self.corpus_tag_ids = [\n",
    "                torch.tensor([self.tag_vocab[tag] for tag in row['IOB Slot tags'].split()])\n",
    "                for _, row in data.iterrows()\n",
    "            ]\n",
    "        else:\n",
    "            self.corpus_tag_ids = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.corpus_token_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.corpus_tag_ids is not None:\n",
    "            return self.corpus_token_ids[idx], self.corpus_tag_ids[idx]\n",
    "        else:\n",
    "            return self.corpus_token_ids[idx], idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "mDc6GOzB8xZw"
   },
   "outputs": [],
   "source": [
    "# Reverse the tag_vocab to map IDs back to tags\n",
    "def ids_to_tags(tag_ids, tag_vocab):\n",
    "    id_to_tag = {id_: tag for tag, id_ in tag_vocab.items()}\n",
    "    return [[id_to_tag[id_] for id_ in seq] for seq in tag_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ceLFivS78xZw"
   },
   "outputs": [],
   "source": [
    "# collate_fn with manually implemented padding\n",
    "def collate_fn(batch):\n",
    "    token_ids = [item[0] for item in batch]\n",
    "    tag_ids = [item[1] for item in batch]\n",
    "\n",
    "    # Calculate original lengths before padding\n",
    "    lengths = [len(seq) for seq in token_ids]\n",
    "\n",
    "    # Determine consistent max length for padding across both tokens and tags\n",
    "    max_length = max(max(len(seq) for seq in token_ids), max(len(seq) for seq in tag_ids))\n",
    "\n",
    "    # Manually pad each sequence in token_ids and tag_ids to max_length\n",
    "    tokens_padded = torch.stack([\n",
    "        F.pad(seq, (0, max_length - len(seq)), value=train_dataset.token_vocab['<PAD>']) for seq in token_ids\n",
    "    ])\n",
    "    tags_padded = torch.stack([\n",
    "        F.pad(seq, (0, max_length - len(seq)), value=train_dataset.tag_vocab['<PAD>']) for seq in tag_ids\n",
    "    ])\n",
    "\n",
    "    assert tokens_padded.shape == tags_padded.shape, f\"Padding mismatch: tokens {tokens_padded.shape}, tags {tags_padded.shape}\"\n",
    "\n",
    "    # print(f\"tokens_padded shape: {tokens_padded.shape}, tags_padded shape: {tags_padded.shape}\")\n",
    "    return tokens_padded, tags_padded, lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "-huwz5kM8xZw"
   },
   "outputs": [],
   "source": [
    "TRAIN_VAL_TEST_SPLIT = \"850/5/10\"\n",
    "\n",
    "df = pd.read_csv('data/hw2_train.csv')\n",
    "df_train, df_valtest = train_test_split(df, test_size=0.15, random_state=42)\n",
    "df_val, df_test = train_test_split(df_valtest, test_size=0.667, random_state=42)\n",
    "\n",
    "train_dataset = SlotTaggingDataset(df_train, training=True)\n",
    "val_dataset = SlotTaggingDataset(df_val, token_vocab=train_dataset.token_vocab, tag_vocab=train_dataset.tag_vocab, training=False)\n",
    "test_dataset = SlotTaggingDataset(df_test, token_vocab=train_dataset.token_vocab, tag_vocab=train_dataset.tag_vocab, training=False)\n",
    "\n",
    "tag_names = list(train_dataset.tag_vocab.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Train Set': 1965, 'Validation Set': 115, 'Test Set': 232},\n",
       " {'Train Set': 0.8499134948096886,\n",
       "  'Validation Set': 0.04974048442906574,\n",
       "  'Test Set': 0.10034602076124567})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_counts = {\n",
    "    \"Train Set\": len(df_train),\n",
    "    \"Validation Set\": len(df_val),\n",
    "    \"Test Set\": len(df_test)\n",
    "}\n",
    "\n",
    "# Calculate proportions\n",
    "total_samples = sum(split_counts.values())\n",
    "split_proportions = {key: count / total_samples for key, count in split_counts.items()}\n",
    "\n",
    "# Display split counts and proportions\n",
    "split_counts, split_proportions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "exEaWotW8xZw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gensim.downloader as api\n",
    "\n",
    "# load 100-dimensional GloVe embeddings\n",
    "# glove = api.load('glove-wiki-gigaword-100')\n",
    "glove = api.load('glove-wiki-gigaword-300')\n",
    "EMBEDDING_DIM = 300\n",
    "\n",
    "def create_embedding_matrix(vocab, word_vectors, embedding_dim=EMBEDDING_DIM):\n",
    "    embedding_matrix = np.random.uniform(-0.1, 0.1, (len(vocab), embedding_dim))\n",
    "    for word, idx in vocab.items():\n",
    "        if word in word_vectors:\n",
    "            embedding_matrix[idx] = word_vectors[word]\n",
    "    return torch.tensor(embedding_matrix, dtype=torch.float)\n",
    "\n",
    "# Create embedding matrix using the Gensim-preloaded embeddings\n",
    "embedding_matrix = create_embedding_matrix(train_dataset.token_vocab, glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "8o3uPUdl8xZw"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "id": "giyxTrxJ8xZw"
   },
   "outputs": [],
   "source": [
    "class SlotTagger(nn.Module):\n",
    "    def __init__(self, vocab_size, tagset_size, embedding_dim, hidden_dim, dropout_prob, pretrained_embeddings=None):\n",
    "        super().__init__()\n",
    "\n",
    "         # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight.data.copy_(torch.tensor(pretrained_embeddings))\n",
    "            # self.embedding.weight.requires_grad = False  # Freeze embedding layer initially\n",
    "\n",
    "        # self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        # self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        # self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, dropout=0.4, batch_first=True, bidirectional=True)\n",
    "        BIDIRECTIONAL = True\n",
    "        NUM_LAYERS = 1\n",
    "        self.dropout = nn.Dropout(dropout_prob)  # Dropout layer with specified probability\n",
    "        self.fc = nn.Linear(hidden_dim*2, tagset_size)\n",
    "        self.tagset_size = tagset_size  # Added this for debug printout in forward\n",
    "\n",
    "    def forward(self, token_ids, lengths):\n",
    "        embeddings = self.embedding(token_ids)\n",
    "        packed_embeds = pack_padded_sequence(embeddings, lengths, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        packed_out, _ = self.rnn(packed_embeds)\n",
    "        rnn_out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        rnn_out = self.dropout(rnn_out)\n",
    "\n",
    "        # Verify rnn_out shape\n",
    "        # print(f\"rnn_out shape: {rnn_out.shape}. Should match (batch_size, {max(lengths)}, {self.rnn.hidden_size})\")\n",
    "        outputs = self.fc(rnn_out)\n",
    "        # Check output shape\n",
    "        # print(f\"outputs shape: {outputs.shape}. Should be (batch_size, {max(lengths)}, {self.tagset_size})\")\n",
    "\n",
    "        assert outputs.shape == (len(token_ids), max(lengths), self.tagset_size), f\"Output shape mismatch: {outputs.shape}\"\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ok2lIp1k8xZw",
    "outputId": "14fa6d9d-71c3-4604-ed38-6a6239c1dd53"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-173-957a98540624>:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.embedding.weight.data.copy_(torch.tensor(pretrained_embeddings))\n"
     ]
    }
   ],
   "source": [
    "# Define model, loss function, and optimizer\n",
    "HIDDEN_DIM = 400\n",
    "LEARNING_RATE = 0.00017\n",
    "DROPOUT_PROB = 0.4\n",
    "\n",
    "NUM_EPOCHS = 200\n",
    "PATIENCE = 9\n",
    "\n",
    "# initialize model, loss function, and optimizer\n",
    "model = SlotTagger(\n",
    "    vocab_size=len(train_dataset.token_vocab),\n",
    "    tagset_size=len(train_dataset.tag_vocab),\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    dropout_prob=DROPOUT_PROB,\n",
    "    pretrained_embeddings=embedding_matrix\n",
    ")\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=train_dataset.tag_vocab['<PAD>'])\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ro0k1PT8xZx",
    "outputId": "8e220643-7601-4956-932c-5b0188346f83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_movie seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_movie seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_country seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: <PAD> seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_mpaa_rating seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_subject seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_person seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_person seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_genre seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_genre seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_director seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_director seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_cast seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_cast seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_producer seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_producer seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_subject seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_language seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_language seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: I_mpaa_rating seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_char seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.525, Val Loss: 1.294, Val F1: 0.000 *\n",
      "Epoch 2, Train Loss: 1.163, Val Loss: 1.067, Val F1: 0.107 *\n",
      "Epoch 3, Train Loss: 1.013, Val Loss: 0.964, Val F1: 0.103 {1}\n",
      "Epoch 4, Train Loss: 0.904, Val Loss: 0.861, Val F1: 0.145 *\n",
      "Epoch 5, Train Loss: 0.767, Val Loss: 0.733, Val F1: 0.189 *\n",
      "Epoch 6, Train Loss: 0.637, Val Loss: 0.616, Val F1: 0.375 *\n",
      "Epoch 7, Train Loss: 0.518, Val Loss: 0.515, Val F1: 0.528 *\n",
      "Epoch 8, Train Loss: 0.420, Val Loss: 0.448, Val F1: 0.523 {1}\n",
      "Epoch 9, Train Loss: 0.347, Val Loss: 0.383, Val F1: 0.561 *\n",
      "Epoch 10, Train Loss: 0.295, Val Loss: 0.338, Val F1: 0.649 *\n",
      "Epoch 11, Train Loss: 0.253, Val Loss: 0.305, Val F1: 0.672 *\n",
      "Epoch 12, Train Loss: 0.222, Val Loss: 0.288, Val F1: 0.675 *\n",
      "Epoch 13, Train Loss: 0.196, Val Loss: 0.262, Val F1: 0.672 {1}\n",
      "Epoch 14, Train Loss: 0.175, Val Loss: 0.238, Val F1: 0.695 *\n",
      "Epoch 15, Train Loss: 0.160, Val Loss: 0.224, Val F1: 0.712 *\n",
      "Epoch 16, Train Loss: 0.144, Val Loss: 0.211, Val F1: 0.726 *\n",
      "Epoch 17, Train Loss: 0.130, Val Loss: 0.198, Val F1: 0.712 {1}\n",
      "Epoch 18, Train Loss: 0.119, Val Loss: 0.191, Val F1: 0.747 *\n",
      "Epoch 19, Train Loss: 0.111, Val Loss: 0.189, Val F1: 0.797 *\n",
      "Epoch 20, Train Loss: 0.101, Val Loss: 0.175, Val F1: 0.786 {1}\n",
      "Epoch 21, Train Loss: 0.093, Val Loss: 0.167, Val F1: 0.788 {2}\n",
      "Epoch 22, Train Loss: 0.087, Val Loss: 0.160, Val F1: 0.814 *\n",
      "Epoch 23, Train Loss: 0.079, Val Loss: 0.159, Val F1: 0.812 {1}\n",
      "Epoch 24, Train Loss: 0.072, Val Loss: 0.155, Val F1: 0.791 {2}\n",
      "Epoch 25, Train Loss: 0.066, Val Loss: 0.147, Val F1: 0.812 {3}\n",
      "Epoch 26, Train Loss: 0.062, Val Loss: 0.150, Val F1: 0.821 *\n",
      "Epoch 27, Train Loss: 0.058, Val Loss: 0.146, Val F1: 0.830 *\n",
      "Epoch 28, Train Loss: 0.054, Val Loss: 0.141, Val F1: 0.817 {1}\n",
      "Epoch 29, Train Loss: 0.052, Val Loss: 0.152, Val F1: 0.821 {2}\n",
      "Epoch 30, Train Loss: 0.047, Val Loss: 0.146, Val F1: 0.821 {3}\n",
      "Epoch 31, Train Loss: 0.044, Val Loss: 0.147, Val F1: 0.821 {4}\n",
      "Epoch 32, Train Loss: 0.041, Val Loss: 0.135, Val F1: 0.831 *\n",
      "Epoch 33, Train Loss: 0.038, Val Loss: 0.142, Val F1: 0.821 {1}\n",
      "Epoch 34, Train Loss: 0.036, Val Loss: 0.141, Val F1: 0.830 {2}\n",
      "Epoch 35, Train Loss: 0.033, Val Loss: 0.140, Val F1: 0.800 {3}\n",
      "Epoch 36, Train Loss: 0.032, Val Loss: 0.139, Val F1: 0.821 {4}\n",
      "Epoch 37, Train Loss: 0.030, Val Loss: 0.136, Val F1: 0.833 *\n",
      "Epoch 38, Train Loss: 0.028, Val Loss: 0.143, Val F1: 0.851 *\n",
      "Epoch 39, Train Loss: 0.027, Val Loss: 0.136, Val F1: 0.842 {1}\n",
      "Epoch 40, Train Loss: 0.025, Val Loss: 0.138, Val F1: 0.826 {2}\n",
      "Epoch 41, Train Loss: 0.023, Val Loss: 0.133, Val F1: 0.838 {3}\n",
      "Epoch 42, Train Loss: 0.022, Val Loss: 0.140, Val F1: 0.842 {4}\n",
      "Epoch 43, Train Loss: 0.020, Val Loss: 0.136, Val F1: 0.838 {5}\n",
      "Epoch 44, Train Loss: 0.020, Val Loss: 0.131, Val F1: 0.838 {6}\n",
      "Epoch 45, Train Loss: 0.018, Val Loss: 0.143, Val F1: 0.838 {7}\n",
      "Epoch 46, Train Loss: 0.018, Val Loss: 0.140, Val F1: 0.851 *\n",
      "Epoch 47, Train Loss: 0.017, Val Loss: 0.136, Val F1: 0.842 {1}\n",
      "Epoch 48, Train Loss: 0.015, Val Loss: 0.141, Val F1: 0.847 {2}\n",
      "Epoch 49, Train Loss: 0.015, Val Loss: 0.137, Val F1: 0.843 {3}\n",
      "Epoch 50, Train Loss: 0.014, Val Loss: 0.137, Val F1: 0.838 {4}\n",
      "Epoch 51, Train Loss: 0.014, Val Loss: 0.134, Val F1: 0.851 *\n",
      "Epoch 52, Train Loss: 0.013, Val Loss: 0.144, Val F1: 0.838 {1}\n",
      "Epoch 53, Train Loss: 0.012, Val Loss: 0.140, Val F1: 0.851 {2}\n",
      "Epoch 54, Train Loss: 0.012, Val Loss: 0.138, Val F1: 0.856 *\n",
      "Epoch 55, Train Loss: 0.012, Val Loss: 0.136, Val F1: 0.851 {1}\n",
      "Epoch 56, Train Loss: 0.011, Val Loss: 0.141, Val F1: 0.856 {2}\n",
      "Epoch 57, Train Loss: 0.010, Val Loss: 0.144, Val F1: 0.838 {3}\n",
      "Epoch 58, Train Loss: 0.009, Val Loss: 0.139, Val F1: 0.856 {4}\n",
      "Epoch 59, Train Loss: 0.009, Val Loss: 0.137, Val F1: 0.856 *\n",
      "Epoch 60, Train Loss: 0.009, Val Loss: 0.141, Val F1: 0.852 {1}\n",
      "Epoch 61, Train Loss: 0.008, Val Loss: 0.137, Val F1: 0.847 {2}\n",
      "Epoch 62, Train Loss: 0.008, Val Loss: 0.135, Val F1: 0.843 {3}\n",
      "Epoch 63, Train Loss: 0.008, Val Loss: 0.141, Val F1: 0.852 {4}\n",
      "Epoch 64, Train Loss: 0.007, Val Loss: 0.145, Val F1: 0.843 {5}\n",
      "Epoch 65, Train Loss: 0.007, Val Loss: 0.139, Val F1: 0.852 {6}\n",
      "Epoch 66, Train Loss: 0.007, Val Loss: 0.148, Val F1: 0.852 {7}\n",
      "Epoch 67, Train Loss: 0.006, Val Loss: 0.137, Val F1: 0.843 {8}\n",
      "Epoch 68, Train Loss: 0.006, Val Loss: 0.142, Val F1: 0.852 {9}\n",
      "Early stopping triggered at epoch 68. Best val F1: 0.856 at Val Loss: 0.137\n"
     ]
    }
   ],
   "source": [
    "version_dir = create_versioned_dir(MODEL_DIR_NAME)\n",
    "\n",
    "# Training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "epochs_no_improve = 0\n",
    "best_val_loss = float('inf')\n",
    "best_val_f1 = 0\n",
    "best_model_state = None\n",
    "\n",
    "# initialize lists to track metrics across epochs\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_f1_scores = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch_idx, (token_ids, tag_ids, lengths) in enumerate(train_loader):\n",
    "        token_ids, tag_ids = token_ids.to(device), tag_ids.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(token_ids, lengths)\n",
    "\n",
    "        # Normal way to flatten outputs and tags to calculate loss\n",
    "        loss = loss_fn(outputs.view(-1, outputs.shape[-1]), tag_ids.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    # Average train loss for epoch\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    # VALIDATION\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    all_preds = []\n",
    "    all_true_tags = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for token_ids, tag_ids, lengths in val_loader:  # Use val_loader here\n",
    "            token_ids, tag_ids = token_ids.to(device), tag_ids.to(device)\n",
    "\n",
    "            outputs = model(token_ids, lengths)\n",
    "            loss = loss_fn(outputs.view(-1, outputs.shape[-1]), tag_ids.view(-1))\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            # Get the predicted tag IDs by taking argmax over the last dimension\n",
    "            predicted_tag_ids = outputs.argmax(dim=-1).cpu().tolist()\n",
    "            true_tag_ids = tag_ids.cpu().tolist()\n",
    "\n",
    "            # Mask out <PAD> tokens from predictions and true tags\n",
    "            masked_predictions = []\n",
    "            masked_true_tags = []\n",
    "\n",
    "            for i, length in enumerate(lengths):\n",
    "                masked_predictions.append(predicted_tag_ids[i][:length])  # Trim predictions to actual length\n",
    "                masked_true_tags.append(true_tag_ids[i][:length])  # Trim true tags to actual length\n",
    "\n",
    "            # Convert ID sequences to tag names\n",
    "            masked_predictions = ids_to_tags(masked_predictions, train_dataset.tag_vocab)\n",
    "            masked_true_tags = ids_to_tags(masked_true_tags, train_dataset.tag_vocab)\n",
    "\n",
    "            # Accumulate all predictions and true tags for F1 calculation\n",
    "            all_preds.extend(masked_predictions)\n",
    "            all_true_tags.extend(masked_true_tags)\n",
    "\n",
    "    # Calculate average validation loss\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_f1 = f1_score(all_true_tags, all_preds)\n",
    "\n",
    "    # Store metrics for plotting\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_f1_scores.append(val_f1)\n",
    "\n",
    "    is_best = val_f1 > best_val_f1 or (val_f1 == best_val_f1 and avg_val_loss < best_val_loss)\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {avg_train_loss:.3f}, Val Loss: {avg_val_loss:.3f}, Val F1: {val_f1:.3f} {\"*\" if is_best else {epochs_no_improve+1}}')\n",
    "\n",
    "    # EARLY STOPPING LOGIC\n",
    "    if val_f1 > best_val_f1 or (val_f1 == best_val_f1 and avg_val_loss < best_val_loss):\n",
    "        # Update best metrics and model state\n",
    "        best_val_loss = avg_val_loss\n",
    "        best_val_f1 = val_f1\n",
    "        epochs_no_improve = 0\n",
    "        best_model_state = model.state_dict()  # Save the best model's state\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}. Best val F1: {best_val_f1:.3f} at Val Loss: {best_val_loss:.3f}\")\n",
    "\n",
    "            # Load the best model state before breaking\n",
    "            model.load_state_dict(best_model_state)\n",
    "\n",
    "            # Save training and validation metrics\n",
    "            training_summary = get_training_summary_json(train_losses, val_losses, val_f1_scores, epoch)\n",
    "            val_results = get_val_results_json(all_true_tags, all_preds, tag_names)\n",
    "            config = get_config_json(\n",
    "                embedding_dim=EMBEDDING_DIM,\n",
    "                hidden_dim=HIDDEN_DIM,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                learning_rate=LEARNING_RATE,\n",
    "                num_epochs=NUM_EPOCHS,\n",
    "                patience=PATIENCE,\n",
    "                dropout_prob=DROPOUT_PROB,\n",
    "                embedding_matrix_name=\"GloVe\",\n",
    "                train_test_split=TRAIN_VAL_TEST_SPLIT,\n",
    "                bidirectional=True,\n",
    "                num_layers=2\n",
    "            )\n",
    "            write_json(config, f\"{version_dir}/config.json\")\n",
    "            write_json(training_summary, f\"{version_dir}/metrics.json\")\n",
    "            write_json(val_results, f\"{version_dir}/val_results.json\")\n",
    "            plot_f1_from_file(version_dir)\n",
    "            plot_loss_from_file(version_dir)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MATWAngZ8xZx"
   },
   "outputs": [],
   "source": [
    "# # Grid search\n",
    "# import itertools\n",
    "\n",
    "# # Define grid of hyperparameters\n",
    "# dropout_options = [0.25, 0.3, 0.35]\n",
    "# lr_options = [0.0008, 0.001, 0.0015]\n",
    "# hidden_dim_options = [512]\n",
    "\n",
    "# # Generate all possible combinations of hyperparameters\n",
    "# param_grid = list(itertools.product(dropout_options, lr_options, hidden_dim_options))\n",
    "\n",
    "\n",
    "\n",
    "# def grid_search(param_grid, model_dir):\n",
    "#     results = []\n",
    "\n",
    "#     for trial, (dropout, learning_rate, hidden_dim) in enumerate(param_grid, start=1):\n",
    "#         print(f\"\\nStarting Trial {trial}/{len(param_grid)} with Dropout: {dropout}, LR: {learning_rate}, Hidden Dim: {hidden_dim}\")\n",
    "\n",
    "#         # Run training and evaluation with these hyperparameters\n",
    "#         val_loss, val_f1 = train_and_evaluate(dropout, learning_rate, hidden_dim, model_dir=model_dir)\n",
    "\n",
    "#         # Record results\n",
    "#         trial_result = {\n",
    "#             \"dropout\": dropout,\n",
    "#             \"learning_rate\": learning_rate,\n",
    "#             \"hidden_dim\": hidden_dim,\n",
    "#             \"val_loss\": val_loss,\n",
    "#             \"val_f1\": val_f1\n",
    "#         }\n",
    "#         results.append(trial_result)\n",
    "\n",
    "#         print(f\"Trial {trial} complete: Val Loss: {val_loss:.3f}, Val F1: {val_f1:.3f}\")\n",
    "\n",
    "#     return results\n",
    "\n",
    "# # Run grid search over all combinations\n",
    "# search_results = grid_search(param_grid, \"model_rnn_dropout_with_glove/grid_search_around_top\")\n",
    "\n",
    "# search_results_df = pd.DataFrame(search_results)\n",
    "# search_results_df.sort_values('val_f1', ascending=False, inplace=True)\n",
    "# search_results_df.reset_index(drop=True, inplace=True)\n",
    "# search_results_df.to_csv(f\"model_rnn_dropout_with_glove/grid_search_around_top/grid_search_results.csv\", index=False)\n",
    "\n",
    "# search_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J5qrto_38xZx",
    "outputId": "749bea21-fad5-426f-b238-bd42459e4827"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test F1 Score: 0.870 | Test Loss: 0.152\n",
      "Saving performance table to 'model_lstm_glove_unfrozen'\n",
      "Performance table saved to 'model_lstm_glove_unfrozen/performance_table.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_location seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: B_release_year seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Test (validation) loop encapsulated\n",
    "\n",
    "model.eval()\n",
    "total_test_loss = 0\n",
    "all_preds = []\n",
    "all_true_tags = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for token_ids, tag_ids, lengths in test_loader:\n",
    "        token_ids, tag_ids = token_ids.to(device), tag_ids.to(device)\n",
    "\n",
    "        # Get model outputs and calculate loss\n",
    "        outputs = model(token_ids, lengths)\n",
    "        loss = loss_fn(outputs.view(-1, outputs.shape[-1]), tag_ids.view(-1))\n",
    "        total_test_loss += loss.item()\n",
    "\n",
    "        # Get predicted and true tag IDs\n",
    "        predicted_tag_ids = outputs.argmax(dim=-1).cpu().tolist()\n",
    "        true_tag_ids = tag_ids.cpu().tolist()\n",
    "\n",
    "        # Trim predictions and true tags to match actual lengths\n",
    "        masked_predictions = [pred[:length] for pred, length in zip(predicted_tag_ids, lengths)]\n",
    "        masked_true_tags = [true[:length] for true, length in zip(true_tag_ids, lengths)]\n",
    "\n",
    "        # Convert ID sequences to tag names\n",
    "        masked_predictions = ids_to_tags(masked_predictions, train_dataset.tag_vocab)\n",
    "        masked_true_tags = ids_to_tags(masked_true_tags, train_dataset.tag_vocab)\n",
    "\n",
    "        # Accumulate all predictions and true tags for F1 calculation\n",
    "        all_preds.extend(masked_predictions)\n",
    "        all_true_tags.extend(masked_true_tags)\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "test_f1 = f1_score(all_true_tags, all_preds)\n",
    "report = classification_report(all_true_tags, all_preds)\n",
    "\n",
    "print(f\"Test F1 Score: {test_f1:.3f} | Test Loss: {avg_test_loss:.3f}\")\n",
    "\n",
    "# Save results\n",
    "test_results = get_test_results_json(avg_test_loss, test_f1, report)\n",
    "\n",
    "write_json(test_results, f\"{version_dir}/test_results.json\")\n",
    "save_performance_table(MODEL_DIR_NAME, all_true_tags, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FTxcB8bg8xZx"
   },
   "outputs": [],
   "source": [
    "plot_loss_from_file(MODEL_DIR_NAME)\n",
    "plot_f1_from_file(MODEL_DIR_NAME)\n",
    "plot_confusion_matrix(MODEL_DIR_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S1iSjgqL8xZx",
    "outputId": "62a7549b-eae0-4dc8-9a4e-4eec808e39b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "Tokens:     ['alfred', 'hitchcock', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "True Tags:  ['B_person', 'I_person', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred Tags:  ['B_director', 'I_director', 'B_movie', 'B_movie', 'B_movie', 'B_movie', 'B_movie', 'B_movie', 'B_movie', 'B_movie']\n",
      "\n",
      "\n",
      "Sample 2:\n",
      "Tokens:     ['find', 'producer', 'of', 'the', 'great', '<UNK>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "True Tags:  ['O', 'O', 'O', 'B_movie', 'I_movie', 'I_movie', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred Tags:  ['O', 'O', 'O', 'B_movie', 'I_movie', 'I_movie', 'B_movie', 'B_movie', 'B_movie', 'B_movie']\n",
      "\n",
      "\n",
      "Sample 3:\n",
      "Tokens:     ['show', 'me', 'a', 'list', 'of', 'movies', 'with', 'r', 'rating', '<PAD>']\n",
      "True Tags:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_mpaa_rating', 'O', '<PAD>']\n",
      "Pred Tags:  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B_mpaa_rating', 'O', 'B_movie']\n",
      "\n",
      "\n",
      "Sample 4:\n",
      "Tokens:     ['pg', 'movies', 'list', 'please', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "True Tags:  ['B_mpaa_rating', 'O', 'O', 'O', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred Tags:  ['B_mpaa_rating', 'O', 'O', 'O', 'B_movie', 'B_movie', 'B_movie', 'B_movie', 'B_movie', 'B_movie']\n",
      "\n",
      "\n",
      "Sample 5:\n",
      "Tokens:     ['how', 'many', 'movies', 'were', 'filmed', 'in', '<UNK>', '<PAD>', '<PAD>', '<PAD>']\n",
      "True Tags:  ['O', 'O', 'O', 'O', 'O', 'O', 'B_location', '<PAD>', '<PAD>', '<PAD>']\n",
      "Pred Tags:  ['O', 'O', 'O', 'O', 'O', 'O', 'B_director', 'B_movie', 'B_movie', 'B_movie']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Debug function\n",
    "\n",
    "def display_sample_outputs(model, data_loader, token_vocab, tag_vocab, n_samples=5):\n",
    "    model.eval()\n",
    "    samples = []\n",
    "\n",
    "    id_to_token = {id_: token for token, id_ in token_vocab.items()}\n",
    "    id_to_tag = {id_: tag for tag, id_ in tag_vocab.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for token_ids, tag_ids, lengths in data_loader:\n",
    "            token_ids, tag_ids = token_ids.to(device), tag_ids.to(device)\n",
    "            outputs = model(token_ids, lengths)\n",
    "            predicted_tag_ids = outputs.argmax(dim=-1).cpu().tolist()\n",
    "            true_tag_ids = tag_ids.cpu().tolist()\n",
    "\n",
    "            for i in range(min(n_samples, len(token_ids))):\n",
    "                tokens = [id_to_token[id_] for id_ in token_ids[i].cpu().tolist()]\n",
    "                true_tags = [id_to_tag[id_] for id_ in true_tag_ids[i]]\n",
    "                pred_tags = [id_to_tag[id_] for id_ in predicted_tag_ids[i]]\n",
    "                samples.append((tokens, true_tags, pred_tags))\n",
    "            break  # Only get samples from the first batch for inspection\n",
    "\n",
    "    # Display the collected samples\n",
    "    for i, (tokens, true_tags, pred_tags) in enumerate(samples):\n",
    "        print(f\"Sample {i + 1}:\")\n",
    "        print(\"Tokens:    \", tokens)\n",
    "        print(\"True Tags: \", true_tags)\n",
    "        print(\"Pred Tags: \", pred_tags)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Run this with both vocabularies on the test loader\n",
    "display_sample_outputs(model, test_loader, train_dataset.token_vocab, train_dataset.tag_vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "caeSUHxl8xZx"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "8Dwkdkux8xZy"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def collate_fn_inference(batch):\n",
    "    token_ids = [item[0] for item in batch]\n",
    "\n",
    "    # Calculate original lengths before padding\n",
    "    lengths = [len(seq) for seq in token_ids]\n",
    "\n",
    "    # Determine max length for consistent padding across all sequences in the batch\n",
    "    max_length = max(len(seq) for seq in token_ids)\n",
    "\n",
    "    # Manually pad each sequence in token_ids to max_length\n",
    "    tokens_padded = torch.stack([\n",
    "        F.pad(seq, (0, max_length - len(seq)), value=train_dataset.token_vocab['<PAD>']) for seq in token_ids\n",
    "    ])\n",
    "\n",
    "    return tokens_padded, lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "5dbrYKMI8xZy"
   },
   "outputs": [],
   "source": [
    "# Load the unseen test data\n",
    "unseen_test_df = pd.read_csv('data/hw2_test.csv')\n",
    "\n",
    "# Create the unseen test dataset\n",
    "unseen_test_dataset = SlotTaggingDataset(\n",
    "    unseen_test_df,\n",
    "    token_vocab=train_dataset.token_vocab,\n",
    "    tag_vocab=train_dataset.tag_vocab,\n",
    "    training=False\n",
    ")\n",
    "\n",
    "# Create a DataLoader for the unseen test set\n",
    "unseen_test_loader = DataLoader(\n",
    "    unseen_test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn_inference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XtglmqKz8xZy",
    "outputId": "1bf1c6b7-4474-4929-cd83-1d26e560b666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 16 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 16 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 16 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 16 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 16 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 16 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 16 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 16 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 16 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 16 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 16 | Expecteded: 16 | Trimmed: 16\n",
      "Prediction: 16 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 16 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 16 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 16 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 16 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 16 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 16 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 16 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 16 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 16 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 11 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 11 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 17 | Expecteded: 17 | Trimmed: 17\n",
      "Prediction: 17 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 17 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 17 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 17 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 17 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 17 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 17 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 17 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 17 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 17 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 17 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 17 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 17 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 17 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 17 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 17 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 17 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 17 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 17 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 17 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 17 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 17 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 17 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 17 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 17 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 17 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 17 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 17 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 17 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 17 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 17 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 13 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 13 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 13 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 13 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 13 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 13 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 13 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 13 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 13 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 13 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 13 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 13 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 13 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 13 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 13 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 13 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 13 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 13 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 13 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 13 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 13 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 13 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 13 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 13 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 13 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 13 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 13 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 13 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 13 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 13 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 13 | Expecteded: 13 | Trimmed: 13\n",
      "Prediction: 13 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 14 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 14 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 14 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 14 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 14 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 14 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 14 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 14 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 14 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 14 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 14 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 14 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 14 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 14 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 14 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 14 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 14 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 14 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 14 | Expecteded: 14 | Trimmed: 14\n",
      "Prediction: 14 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 14 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 14 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 14 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 14 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 14 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 15 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 15 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 15 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 15 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 15 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 15 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 15 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 15 | Expecteded: 15 | Trimmed: 15\n",
      "Prediction: 15 | Expecteded: 1 | Trimmed: 1\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 15 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 15 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 15 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 15 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 15 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 15 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 15 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 15 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 15 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 9 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 9 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 9 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 9 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 9 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 9 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 1 | Trimmed: 1\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 9 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 9 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 9 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 9 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 9 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 9 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 9 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 9 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 9 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 9 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 9 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 9 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 9 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 9 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 9 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 9 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 9 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 9 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 9 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 9 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 9 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 9 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 9 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 9 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 9 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 9 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 9 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 9 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 9 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 11 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 14 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 13 | Trimmed: 13\n",
      "Prediction: 14 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 14 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 14 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 14 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 14 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 14 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 14 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 14 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 14 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 14 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 14 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 14 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 14 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 14 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 14 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 14 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 14 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 14 | Expecteded: 14 | Trimmed: 14\n",
      "Prediction: 14 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 12 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 12 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 12 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 11 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 11 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 17 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 17 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 17 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 17 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 17 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 17 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 17 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 17 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 17 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 17 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 17 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 17 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 17 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 17 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 17 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 17 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 17 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 17 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 17 | Expecteded: 16 | Trimmed: 16\n",
      "Prediction: 17 | Expecteded: 17 | Trimmed: 17\n",
      "Prediction: 17 | Expecteded: 13 | Trimmed: 13\n",
      "Prediction: 17 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 17 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 17 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 17 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 17 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 17 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 17 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 17 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 17 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 17 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 17 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 9 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 9 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 9 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 9 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 9 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 9 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 9 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 9 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 9 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 9 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 9 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 9 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 9 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 9 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 9 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 10 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 10 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 10 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 10 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 10 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 10 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 10 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 10 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 10 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 10 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 10 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 10 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 10 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 10 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 10 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 10 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 10 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 10 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 10 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 10 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 10 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 10 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 10 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 10 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 10 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 10 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 10 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 10 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 10 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 10 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 10 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 10 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 19 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 19 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 19 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 19 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 19 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 19 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 19 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 19 | Expecteded: 13 | Trimmed: 13\n",
      "Prediction: 19 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 19 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 19 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 19 | Expecteded: 13 | Trimmed: 13\n",
      "Prediction: 19 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 19 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 19 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 19 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 19 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 19 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 19 | Expecteded: 14 | Trimmed: 14\n",
      "Prediction: 19 | Expecteded: 14 | Trimmed: 14\n",
      "Prediction: 19 | Expecteded: 18 | Trimmed: 18\n",
      "Prediction: 19 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 19 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 19 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 19 | Expecteded: 16 | Trimmed: 16\n",
      "Prediction: 19 | Expecteded: 19 | Trimmed: 19\n",
      "Prediction: 19 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 19 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 19 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 19 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 19 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 19 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 1 | Trimmed: 1\n",
      "Prediction: 11 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 11 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 11 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 11 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 11 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 1 | Trimmed: 1\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 22 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 22 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 22 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 22 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 22 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 22 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 22 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 22 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 22 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 22 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 22 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 22 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 22 | Expecteded: 22 | Trimmed: 22\n",
      "Prediction: 22 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 22 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 22 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 22 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 22 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 22 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 22 | Expecteded: 17 | Trimmed: 17\n",
      "Prediction: 22 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 22 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 22 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 22 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 22 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 22 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 22 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 22 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 22 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 22 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 22 | Expecteded: 13 | Trimmed: 13\n",
      "Prediction: 22 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 12 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 12 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 13 | Trimmed: 13\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 15 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 15 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 15 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 15 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 15 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 15 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 15 | Expecteded: 15 | Trimmed: 15\n",
      "Prediction: 15 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 15 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 15 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 15 | Expecteded: 13 | Trimmed: 13\n",
      "Prediction: 15 | Expecteded: 15 | Trimmed: 15\n",
      "Prediction: 15 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 15 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 14 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 14 | Expecteded: 14 | Trimmed: 14\n",
      "Prediction: 14 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 14 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 14 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 14 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 14 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 14 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 14 | Expecteded: 2 | Trimmed: 2\n",
      "Prediction: 14 | Expecteded: 13 | Trimmed: 13\n",
      "Prediction: 14 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 14 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 14 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 14 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 14 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 14 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 14 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 14 | Expecteded: 14 | Trimmed: 14\n",
      "Prediction: 14 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 14 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 14 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 14 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 14 | Expecteded: 14 | Trimmed: 14\n",
      "Prediction: 14 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 14 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 16 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 16 | Trimmed: 16\n",
      "Prediction: 16 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 16 | Expecteded: 13 | Trimmed: 13\n",
      "Prediction: 16 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 16 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 16 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 16 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 16 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 16 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 16 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 16 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 16 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 16 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 16 | Expecteded: 13 | Trimmed: 13\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 15 | Expecteded: 15 | Trimmed: 15\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 15 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 15 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 15 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 15 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 15 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 15 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 15 | Expecteded: 8 | Trimmed: 8\n",
      "Prediction: 15 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 15 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 15 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 15 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 15 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 3 | Trimmed: 3\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 10 | Trimmed: 10\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 5 | Trimmed: 5\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 12 | Trimmed: 12\n",
      "Prediction: 12 | Expecteded: 4 | Trimmed: 4\n",
      "Prediction: 12 | Expecteded: 7 | Trimmed: 7\n",
      "Prediction: 12 | Expecteded: 6 | Trimmed: 6\n",
      "Prediction: 12 | Expecteded: 9 | Trimmed: 9\n",
      "Prediction: 12 | Expecteded: 11 | Trimmed: 11\n",
      "Prediction: 12 | Expecteded: 8 | Trimmed: 8\n"
     ]
    }
   ],
   "source": [
    "# Run inference on the Kaggle test data\n",
    "model.eval()\n",
    "all_preds_raw = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for token_ids, lengths in unseen_test_loader:\n",
    "        token_ids = token_ids.to(device)\n",
    "\n",
    "        # Get model outputs\n",
    "        outputs = model(token_ids, lengths)\n",
    "        predicted_tag_ids = outputs.argmax(dim=-1).cpu().tolist()\n",
    "\n",
    "        # Trim predictions to match actual sequence lengths\n",
    "        trimmed_predictions = [pred[:length] for pred, length in zip(predicted_tag_ids, lengths)]\n",
    "\n",
    "        for i, length in enumerate(lengths):\n",
    "            print(f\"Prediction: {len(predicted_tag_ids[i])} | Expecteded: {length} | Trimmed: {len(trimmed_predictions[i])}\")\n",
    "\n",
    "        # Convert ID sequences to tag names\n",
    "        trimmed_tags = ids_to_tags(trimmed_predictions, train_dataset.tag_vocab)\n",
    "\n",
    "        # Collect predictions for all batches\n",
    "        all_preds.extend(trimmed_tags)\n",
    "\n",
    "        # Collect raw predictions for debugging\n",
    "        raw_tags = ids_to_tags(predicted_tag_ids, train_dataset.tag_vocab)\n",
    "        all_preds_raw.extend(raw_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4ZJ0HiU8xZy",
    "outputId": "653943b9-216f-442a-b658-f1ba2ebeaba5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as 'submission.csv'\n",
      "Debugging submission file saved as 'submission_debug.csv'\n"
     ]
    }
   ],
   "source": [
    "# Prepare the predictions for submission\n",
    "submission = pd.DataFrame({\n",
    "    'ID': unseen_test_df['ID'],\n",
    "    'IOB Slot tags': [' '.join(tags) for tags in all_preds]\n",
    "})\n",
    "\n",
    "# Save submission file\n",
    "submission.to_csv(f'{version_dir}/submission.csv', index=False)\n",
    "print(\"Submission file saved as 'submission.csv'\")\n",
    "\n",
    "# Debugging submission\n",
    "submission_debug = pd.DataFrame({\n",
    "    'ID': unseen_test_df['ID'],\n",
    "    'utterances': unseen_test_df['utterances'],\n",
    "    'IOB Slot tags': [' '.join(tags) for tags in all_preds],\n",
    "    'IOB Slot tags Raw': [' '.join(tags) for tags in all_preds_raw]\n",
    "})\n",
    "\n",
    "submission_debug.to_csv(f'{version_dir}/submission_debug.csv', index=False)\n",
    "print(\"Debugging submission file saved as 'submission_debug.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0gJU6Pps8xZy"
   },
   "source": [
    "#### Plots"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
